# What we wanted to learn

**Our goals for this research were to:**

1. Evaluate how grantees react to concept prototypes simulating TANF report creation (e.g. capturing metadata) and the uploading of associated flat files. 

2. Identify how grantees track the status (e.g., drafted, edited, submitted, resubmitted) of their data reports and maintain transparency of that status across their teams. 
   - Document how grantees confirm that a report has any given status. 
   - Identify if/how grantees maintain a log of what reports they submitted to OFA. 
   - Identify if/how grantees maintain a version history of resubmitted TANF reports (e.g. what was added, updated or deleted) as if/how they save older versions. 
3. Document the makeup of grantee teams involved with data preparation and data submission.
   - Identify if/how grantees maintain a version history of resubmitted TANF reports (e.g. what was added, updated or deleted) as if/how they save older versions. 
     - The spring research gave us an understanding of what data-preppers do but we hope to dig deeper into how teams of data preppers (when they exist) divide responsibilities and interact with each other.   
   - Identify any common roles aligned to admin tasks (e.g. User Management or onboarding new users to data-prep or case management tools) and document how these tasks are managed.
   - Identify team grantees turnover rates and any associated pain points.
4. Deepen our understanding of how grantees create flat files and what causes metadata issues (including title, header, and trailer)  
   - Document how grantees manage their data (e.g. any case management systems, excel files, etc.) and compare TANF reports to how grantees structure and store their data.  
     - The spring research helped us understand how grantees code data from a variety of local or regional resources but we hope to uncover the pain points that might be outside the flow of submitting to OFA but still have an impact on data quality and data management practices relevant to resubmission. 
   - Document the process of coding information from grantee case management systems into TANF report metadata.
     - While the spring research documented coding fixes (and the difficulty of making those fixes), we want to deepen our understanding the circumstances that lead to the need for these coding fixes. 



Related Documentation:

[Full research plan](<https://hhsgov.sharepoint.com/:w:/r/sites/TANFDataPortalOFA-UserResearch/Shared%20Documents/User%20Research/STT%20Research%20September%202020/%2363%20User%20Research%20Plan%20STTs.docx?d=w2e300237f6454446b191a9ee509026ef&csf=1&web=1&e=pAteXb>)🔒



# Who we talked to

Given the largely generative focus of this research we wanted to talk to 5-9 participants involved in TANF data preparation from a variety of grantee types. We targeted criteria such as: 

- At least one state that submits universal case data
- At least one state that submits sample data
- At least one tribe
- At least one territory
- Preferance toward participants who have no been interviewed in past research

We ended up talking to a total of six participants who fulfilled all of the above criteria. Those participants represented one tribe, one territory, and four states. Sessions ranged from 1 hour to 1 hour and 25 minutes and was equally divided into one half focused on generative interview questions regarding research goals 2-4 and one half moving through the conceptual prototypes.



Related Documentation:

[Recruiting Criteria and Selection](<https://hhsgov.sharepoint.com/:w:/r/sites/TANFDataPortalOFA-UserResearch/_layouts/15/WopiFrame2.aspx?sourcedoc=%7B1a533a84-0000-423d-8274-c0767d9f471d%7D&action=view&cid=ad0b98e3-1d2b-46ad-a6f3-50eb0c019c01>) 🔒

[Grantee Attributes](<https://hhsgov.sharepoint.com/:x:/r/sites/TANFDataPortalOFA-UserResearch/_layouts/15/WopiFrame2.aspx?sourcedoc=%7Be83f84f1-71a0-459f-80a4-0d39bc250be9%7D&action=view&cid=f2e656cb-9245-4f02-af6d-2d7e1db6573d>) 🔒



# What we tested

Concept testing was focused around a flow depicting the process of report creation. It started from a screen collecting report metadata (e.g. Reporting Year/Quarter, whether the report is TANF or SSP-MOE, etc...), went through flat file upload, metadata validation, and a summary of successfully validated files.



Related Documentation:

[Figma Prototype 1](<https://www.figma.com/proto/y15co5xc7MIZXBnWBOF6hJ/Conceptual-Mockups-for-STT-Feedback?node-id=9%3A332&viewport=187%2C385%2C0.11285778135061264&scaling=min-zoom>)

[Figma Prototype 2](<https://www.figma.com/proto/y15co5xc7MIZXBnWBOF6hJ/Conceptual-Mockups-for-STT-Feedback?node-id=1%3A1070&viewport=530%2C320%2C0.1293068528175354&scaling=min-zoom>)

[PDF Prototype 1 & 2](<https://github.com/HHS/TANF-app/tree/main/docs/User%20Research/2020%2C%20Fall%20-%20Concept%20Prototypes>)



# What we learned

Raw notes from interviews were synthesized in Mural with the OFA data division. Then we distilled our learning further into the insights below.



**About error validation & correction**

- Grantees have different processes to correct errors in a flat file, which may have implications for the long-term quality of the data.
- Corrections made for ACF acceptance do not necessarily get applied to the source data
- Grantees want more efficient and more actionable ways to understand the errors (validation, transmission, etc.) and how to fix them. 



**About case management systems and other tools**

- [Some case management systems are multipurpose with some degree of customization for TANF.](#Some-case-management-systems-are-multipurpose-with-some-degree-of-customization-for-TANF)
- TANF staff are navigating multiple software products from data collection through report submission.
- Editing often happens in case management tools, but a few tasks are completed directly in the flat file (in a text editor).



**About grantee teams**

- "Data Prepper" may be a broader role in the reality of grantees than our current definition does justice to.
- Report generation is a somewhat manual process that can involve different offices and multiple team members.
- Responsibility over parts of the prep/submission process fall entirely on one or two people in some grantee teams
- Multiple people own different parts of the TANF report creation and submission process. There is a lack of autonomy of the overall process. Vendor teams play different roles based on the grantee they are associated with—TANF staff do not have control over whole data system or data process.



**About the data transmission process**

- Some grantees store a copy of flat file (TANF report) that was transmitted to ACF. Some grantees use the transmitted copy to build on future TANF reports which may continue to transmit errors.

- Grantees want to submit quality data even if deadlines have passed

- Grantees sometimes have to communicate with ACF to determine transmission status—Grantees look for clear, timely confirmation that a file was received.

- Grantees have different ways of uploading files; upload function should be flexible

  

**About the concept prototypes (and terminology)** 

- There is confusion about fiscal year and calendar year reporting.
- Grantees understood the term 'encryption' differently.
- ACF TANF file naming conventions aren't familiar to all those involved in prepping data



**Refine or consider these some more?**

- Grantees have various way to create flat files. Vendors often play a key part in flat file creation—[Strikes me that this isn't really something we learned or thought needed validation]
- Grantees understood the concept prototype but used different termonology to refer to different sections—[Definitely validation teritorry rather than new learning (see Spring 2020 research findings)]



Related Documentation

[Synthesis Workshop  Mural](https://app.mural.co/t/officeoffamilyassistance2744/m/officeoffamilyassistance2744/1605279076254/8ba4f36f5bc1b2d724fd8c61daf6dc18da096e97) 🔒



## About error validation & correction

### Grantees want more efficient and more actionable ways to understand the errors (validation, transmission, etc.) and how to fix them 

Most of the grantees we spoke to had relatively low rates of fatal errors when submitting their data, but all dealt on some level with either reviewing files for data quality issues, or navigating corrections of files when issuess ocurred. One participant gave us a great view into the sheer scale of possible errors & edits by pulling out their "book"—a large binder containing printed versions of ACF error codes. They told us:

- "So after [ACF has the data] this is how the feedback comes up to us. The cases are here and here [folder of a variety of PDF reports, it says error flag. So it tells me this case has an error and what the error flag is. So again, I kind of go, you know, try the little book."
- "...it'd be good if instead of looking through a book, you know, something will pop up and say, this is what's what's missing, or this is what you need to correct. Because if not, then I have to kind of go through my little binder and I go to the federal edits guide"

They expanded with an example of how this process isn't always as simple as looking up a single code, but rather crossreferencing multiple data points against multiple error codes and/or data coding instructions:

- "What can be a little challenging is it's going to give you the element number. It's going to say parents with minor child and the family. Then it says if item 14 equals one to two item 22 must equal one to two. So what I have to do is on our ACF instructional guide, look for what is item 14. So I have to go to my book."



**Project Impacts**

- Consider how we might lean *more* into making errors highly understandable and highly actionable—Participants we tested the concept prototype were able to rephrase what was being conveyed by our error copy in their own words, but it was a pretty simplistic error. We should think about how we'll scale writing easy-to-interperet error copy for the broader picture of errors possible for any given report. 
- The "in your own words" explainations from participants of what our error copy meant could be helpful for our iteration on it. 



## About case management systems and other tools

### Some case management systems are multipurpose with some degree of customization for TANF.

Multiple grantees spoke to how one or more of the software tools they use served some degree of double-duty for other offices or departments in their governments. 

- Grantee showed us a terminal-interface system that included menus for other programs including SNAP and Medicaid as well as TANF. 
- "We call it [single source of truth vendor system] the green screen, the green letterings, we call it the green screen. That's actually the platform which is used government wide"
- "We use the public health version [of vendor system] with our specific menus and that was built with a local vendor"



### Editing often happens in case management tools, but a few tasks are completed directly in the flat file (in a text editor)

One participant we spoke to carries out the responsibility of submitting the final year-end data to ACF leading up to the reporting deadline. This involved assembling a single flat file by copying and pasting the entirety of flat files into a blank text file to combine them into a single one. 

-  "If I'm submitting multiple quarters, then I basically merge the files..."



## About the concept prototypes (and terminology)

### Grantees understand the term 'encryption' differently. 

Some grantees seemed to understood encryption as being something roughly equivelenat to 'non human-readable'. Others did connect our question about encryption with the TANF header data point regarding social security numbers (SSN). However not all encrypt those, instead relying on security inherent to the SFTP/Vendor transfer processes:

- "We count on the TIBCO [cyberfusion] process to make the data secure...We don't bother encrypting the SSNs"

Other grantees spoke to quirks of their software tools related to SSN encryption, saying that sometimes metadata sometimes has to be changed to get report file imports to work properly: 

- "...when we do [import] the first time we have to put “no”. Yeah. For some reason we have to, re-import it. We have to put "yes" in order to see it" 



